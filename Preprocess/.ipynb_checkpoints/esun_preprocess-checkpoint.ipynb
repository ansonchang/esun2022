{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ddb33b6-56ab-40ca-8571-dcff1eea34ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "897bfb4a-3273-4a33-b926-b4692d46685c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.0.0.rc4'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pycaret.utils import version\n",
    "version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b0071c4-6c42-46db-a6c8-034210f5c559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_n(pred_p, true_l):\n",
    "    '''metric Recall@N'''\n",
    "    n, cur_sum = sum(true_l), 0\n",
    "    rank_pair = sorted(zip(pred_p,true_l),key=lambda x: x[0],reverse=True)\n",
    "    for i, (_p, _l) in enumerate(rank_pair):\n",
    "        cur_sum += _l\n",
    "        if cur_sum==n:\n",
    "            return n/(i+1)\n",
    "        \n",
    "def recall_n_1(pred_p, true_l):\n",
    "    '''metric Recall@N-1'''\n",
    "    n, cur_sum = sum(true_l)-1, 0\n",
    "    rank_pair = sorted(zip(pred_p,true_l),key=lambda x: x[0],reverse=True)\n",
    "    for i, (_p, _l) in enumerate(rank_pair):\n",
    "        cur_sum += _l\n",
    "        if cur_sum==n:\n",
    "            return n/(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf324fe6-07a6-4e47-9a38-7c26564e9dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cust=pd.read_csv('../../data/public_train_x_custinfo_full_hashed.csv')\n",
    "ccba=pd.read_csv('../../data/public_train_x_ccba_full_hashed.csv')\n",
    "cdtx=pd.read_csv('../../data/public_train_x_cdtx0001_full_hashed.csv')\n",
    "dp=pd.read_csv('../../data/public_train_x_dp_full_hashed.csv')\n",
    "remit=pd.read_csv('../../data/public_train_x_remit1_full_hashed.csv')\n",
    "alert_test=pd.read_csv('../../data/public_x_alert_date.csv')\n",
    "\n",
    "alert_train=pd.read_csv('../../data/train_x_alert_date.csv')\n",
    "y_train=pd.read_csv('../../data/train_y_answer.csv')\n",
    "y_test=pd.read_csv('../../data/Sample.csv')\n",
    "\n",
    "cust_private=pd.read_csv('../../data/private_x_custinfo_full_hashed.csv')\n",
    "ccba_private=pd.read_csv('../../data/private_x_ccba_full_hashed.csv')\n",
    "cdtx_private=pd.read_csv('../../data/private_x_cdtx0001_full_hashed.csv')\n",
    "dp_private=pd.read_csv('../../data/private_x_dp_full_hashed.csv')\n",
    "remit_private=pd.read_csv('../../data/private_x_remit1_full_hashed.csv')\n",
    "alert_test_private=pd.read_csv('../../data/private_x_alert_date.csv')\n",
    "\n",
    "cust=pd.concat([cust,cust_private],axis=0).reset_index(drop=True)\n",
    "ccba=pd.concat([ccba,ccba_private],axis=0).reset_index(drop=True)\n",
    "cdtx=pd.concat([cdtx,cdtx_private],axis=0).reset_index(drop=True)\n",
    "dp=pd.concat([dp,dp_private],axis=0).reset_index(drop=True)\n",
    "remit=pd.concat([remit,remit_private],axis=0).reset_index(drop=True)\n",
    "alert_test=pd.concat([alert_test,alert_test_private],axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bdd96e9-78ee-4a0c-8492-a7f3f075b5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccb92799-4afa-447f-90a9-7c6178159ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate dataset (date<=290)\n",
    " \n",
    "y_test['sar_flag']=np.nan\n",
    "\n",
    "alert_all=pd.concat([alert_train,alert_test],axis=0)\n",
    "\n",
    "y_all=pd.concat([y_train,y_test[['alert_key','sar_flag']]],axis=0)\n",
    "\n",
    "all_data = pd.merge(y_all,cust,how='left')\n",
    "all_data = pd.merge(all_data,alert_all,how='left')\n",
    "\n",
    "all_date1=all_data[(all_data.date<=290)]\n",
    "\n",
    "all_date2=all_data[all_data.sar_flag.isnull()]\n",
    "\n",
    "all_data=pd.concat([all_date1, all_date2], axis=0)\n",
    "\n",
    "dp1_agg = dp.groupby(['cust_id','tx_date']).agg({\n",
    "    'ATM':['sum','count'],\n",
    "}).reset_index()\n",
    "dp1_agg.columns = ['_'.join([f'{y}' for y in x if y]) for x in dp1_agg.columns]\n",
    "dp1_agg['ATM_rate']=dp1_agg.ATM_sum/dp1_agg.ATM_count\n",
    "\n",
    "dp1_agg.columns=['cust_id', 'date', 'ATM_sum','daily_count','ATM_rate']\n",
    "all_data = pd.merge(all_data,dp1_agg,on=['cust_id','date'],how='left')\n",
    "\n",
    "dp_agg = dp.groupby(['cust_id','tx_date','tx_type']).agg({\n",
    "    'tx_amt': ['max','mean','std']\n",
    "}).unstack().reset_index()\n",
    "dp_agg.columns = ['_'.join([f'{y}' for y in x if y]) for x in dp_agg.columns]\n",
    "\n",
    "dp_agg.columns=['cust_id', 'date', 'tx_amt_max_1', 'tx_amt_max_2', 'tx_amt_max_3',\n",
    "       'tx_amt_mean_1', 'tx_amt_mean_2', 'tx_amt_mean_3', 'tx_amt_std_1',\n",
    "       'tx_amt_std_2', 'tx_amt_std_3']\n",
    "\n",
    "all_data = pd.merge(all_data,dp_agg,on=['cust_id','date'],how='left')\n",
    "\n",
    "all_data['AGE']=all_data['AGE'].astype('category') \n",
    "AGE_ohe = pd.get_dummies(all_data[['AGE']])\n",
    "all_data=pd.concat([all_data, AGE_ohe], axis=1)\n",
    "\n",
    "all_data['occupation_code']=all_data['occupation_code'].astype('category') \n",
    "occupation_code_ohe = pd.get_dummies(all_data[['occupation_code']])\n",
    "all_data=pd.concat([all_data, occupation_code_ohe], axis=1)\n",
    "\n",
    "all_data=all_data.drop(['AGE','occupation_code'], axis=1)\n",
    "\n",
    "date_agg=all_data.groupby(['cust_id']).agg({'date': ['count']}).reset_index()\n",
    "date_agg.columns = ['_'.join([str(y) for y in x if y]) for x in date_agg.columns]\n",
    "all_data = pd.merge(all_data,date_agg,on=['cust_id'],how='left')\n",
    "\n",
    "seed=42\n",
    "\n",
    "df_train_all=all_data[all_data.sar_flag.notnull()]\n",
    "df_test=all_data[all_data.sar_flag.isnull()]\n",
    "\n",
    "custMaxDate_train={}\n",
    "for i, _id in enumerate(df_train_all['cust_id'].unique()):\n",
    "    date_max=df_train_all[df_train_all['cust_id']==_id].date.max()\n",
    "    custMaxDate_train[_id]=date_max\n",
    "df_train_maxdate =pd.DataFrame(custMaxDate_train.items(), columns=['cust_id', 'maxdate'])\n",
    "df_train_all=pd.merge(df_train_all,df_train_maxdate, how='left')\n",
    "\n",
    "custMaxDate_test={}\n",
    "for i, _id in enumerate(df_test['cust_id'].unique()):\n",
    "    date_max=df_test[df_test['cust_id']==_id].date.max()\n",
    "    custMaxDate_test[_id]=date_max\n",
    "df_test_maxdate =pd.DataFrame(custMaxDate_test.items(), columns=['cust_id', 'maxdate'])\n",
    "df_test=pd.merge(df_test,df_test_maxdate, how='left')\n",
    "\n",
    "df_train_all['maxdate_dif']=df_train_all['maxdate']-df_train_all['date']\n",
    "df_test['maxdate_dif']=df_test['maxdate']-df_test['date']\n",
    "\n",
    "df_train=df_train_all.copy()\n",
    "\n",
    "df_test.to_csv('../csv/df_test.csv', index=False)\n",
    "\n",
    "df_train.to_csv('../csv/df_train_290.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faf385c2-3514-43bc-a04a-863db0b1a03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate dataset (date<=280)\n",
    "\n",
    "y_test['sar_flag']=np.nan\n",
    "\n",
    "alert_all=pd.concat([alert_train,alert_test],axis=0)\n",
    "\n",
    "y_all=pd.concat([y_train,y_test[['alert_key','sar_flag']]],axis=0)\n",
    "\n",
    "all_data = pd.merge(y_all,cust,how='left')\n",
    "all_data = pd.merge(all_data,alert_all,how='left')\n",
    "\n",
    "all_date1=all_data[(all_data.date<=280)]\n",
    "\n",
    "all_date2=all_data[all_data.sar_flag.isnull()]\n",
    "\n",
    "all_data=pd.concat([all_date1, all_date2], axis=0)\n",
    "\n",
    "dp1_agg = dp.groupby(['cust_id','tx_date']).agg({\n",
    "    'ATM':['sum','count'],\n",
    "}).reset_index()\n",
    "dp1_agg.columns = ['_'.join([f'{y}' for y in x if y]) for x in dp1_agg.columns]\n",
    "dp1_agg['ATM_rate']=dp1_agg.ATM_sum/dp1_agg.ATM_count\n",
    "\n",
    "dp1_agg.columns=['cust_id', 'date', 'ATM_sum','daily_count','ATM_rate']\n",
    "all_data = pd.merge(all_data,dp1_agg,on=['cust_id','date'],how='left')\n",
    "\n",
    "dp_agg = dp.groupby(['cust_id','tx_date','tx_type']).agg({\n",
    "    'tx_amt': ['max','mean','std']\n",
    "}).unstack().reset_index()\n",
    "dp_agg.columns = ['_'.join([f'{y}' for y in x if y]) for x in dp_agg.columns]\n",
    "\n",
    "dp_agg.columns=['cust_id', 'date', 'tx_amt_max_1', 'tx_amt_max_2', 'tx_amt_max_3',\n",
    "       'tx_amt_mean_1', 'tx_amt_mean_2', 'tx_amt_mean_3', 'tx_amt_std_1',\n",
    "       'tx_amt_std_2', 'tx_amt_std_3']\n",
    "\n",
    "all_data = pd.merge(all_data,dp_agg,on=['cust_id','date'],how='left')\n",
    "\n",
    "all_data['AGE']=all_data['AGE'].astype('category') \n",
    "AGE_ohe = pd.get_dummies(all_data[['AGE']])\n",
    "all_data=pd.concat([all_data, AGE_ohe], axis=1)\n",
    "\n",
    "all_data['occupation_code']=all_data['occupation_code'].astype('category') \n",
    "occupation_code_ohe = pd.get_dummies(all_data[['occupation_code']])\n",
    "all_data=pd.concat([all_data, occupation_code_ohe], axis=1)\n",
    "\n",
    "all_data=all_data.drop(['AGE','occupation_code'], axis=1)\n",
    "\n",
    "date_agg=all_data.groupby(['cust_id']).agg({'date': ['count']}).reset_index()\n",
    "date_agg.columns = ['_'.join([str(y) for y in x if y]) for x in date_agg.columns]\n",
    "all_data = pd.merge(all_data,date_agg,on=['cust_id'],how='left')\n",
    "\n",
    "seed=42\n",
    "\n",
    "df_train_all=all_data[all_data.sar_flag.notnull()]\n",
    "df_test=all_data[all_data.sar_flag.isnull()]\n",
    "\n",
    "custMaxDate_train={}\n",
    "for i, _id in enumerate(df_train_all['cust_id'].unique()):\n",
    "    date_max=df_train_all[df_train_all['cust_id']==_id].date.max()\n",
    "    custMaxDate_train[_id]=date_max\n",
    "df_train_maxdate =pd.DataFrame(custMaxDate_train.items(), columns=['cust_id', 'maxdate'])\n",
    "df_train_all=pd.merge(df_train_all,df_train_maxdate, how='left')\n",
    "\n",
    "custMaxDate_test={}\n",
    "for i, _id in enumerate(df_test['cust_id'].unique()):\n",
    "    date_max=df_test[df_test['cust_id']==_id].date.max()\n",
    "    custMaxDate_test[_id]=date_max\n",
    "df_test_maxdate =pd.DataFrame(custMaxDate_test.items(), columns=['cust_id', 'maxdate'])\n",
    "df_test=pd.merge(df_test,df_test_maxdate, how='left')\n",
    "\n",
    "df_train_all['maxdate_dif']=df_train_all['maxdate']-df_train_all['date']\n",
    "df_test['maxdate_dif']=df_test['maxdate']-df_test['date']\n",
    "\n",
    "df_train=df_train_all.copy()\n",
    "\n",
    "\n",
    "df_train.to_csv('../csv/df_train_280.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d09bdf5-fe4f-41cf-a41f-c5ada497a99d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycaret",
   "language": "python",
   "name": "pycaret"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
